\paragraph{Harmfulness w/ Adversarial Prompting - \moderate}
In the scenario with adversarial prompting, the model's harmfulness risk level is assessed as moderate. When compared to its performance without adversarial inputs, the model demonstrates a larger number of failed cases across the subcategories. This indicates that while the model has mechanisms in place to deal with potentially harmful content, the introduction of adversarial prompts reveals areas where these mechanisms can be bypassed or are less effective. The moderate risk level highlights the need for further refinement of the model's understanding and safeguards to better protect against the nuanced challenges presented by adversarial prompting.
\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/Harmfulness_Adv_1_breakdown.png}
    \vspace{-0.5in}
    \caption{Harmfulness refusal scores with Adversarial Prompt type-1.}
\end{figure*} 

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/harmfulness_adv1_barchart.png}
    % \vspace{-0.5in}
    \caption{Jailbreak rate of sub categories with Adversarial Prompt type-1.}
\end{figure*} 

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/Harmfulness_Adv_2_breakdown.png}
    \vspace{-0.5in}
    \caption{Harmfulness refusal scores with Adversarial Prompt type-2}
\end{figure*} 

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/harmfulness_adv2_barchart.png}
    % \vspace{-0.5in}
    \caption{Jailbreak rate of sub categories with Adversarial Prompt type-2.}
\end{figure*} 
\input{Content/harmfulness/harmfulness_adv_example}