\paragraph{Harmfulness w/ Adversarial Prompting - \high}
With the introduction of two adversarial prompts, the model's harmfulness risk level escalates to high, showing a significant increase in failed cases compared to the evaluation without adversarial prompting. This suggests that adversarial inputs exacerbate the model's vulnerabilities, leading to a higher risk of generating harmful content across a broad range of subcategories. The high risk level underlines critical gaps in the model's safety mechanisms and its ability to discern and mitigate harmful content under adversarial conditions. It emphasizes the urgent need for comprehensive improvements to ensure the model can withstand adversarial attempts to elicit harmful outputs effectively.
\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/Harmfulness_Adv_1_breakdown.png}
    \vspace{-0.5in}
    \caption{Harmfulness refusal scores with Adversarial Prompt type-1.}
\end{figure*} 

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/harmfulness_adv1_barchart.png}
    % \vspace{-0.5in}
    \caption{Jailbreak rate of sub categories with Adversarial Prompt type-1.}
\end{figure*} 

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/Harmfulness_Adv_2_breakdown.png}
    \vspace{-0.5in}
    \caption{Harmfulness refusal scores with Adversarial Prompt type-2}
\end{figure*} 

\begin{figure*}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{Images/harmfulness_adv2_barchart.png}
    % \vspace{-0.5in}
    \caption{Jailbreak rate of sub categories with Adversarial Prompt type-2.}
\end{figure*} 
\input{Content/harmfulness/harmfulness_adv_example}