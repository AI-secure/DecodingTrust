\subsubsection*{Harmfulness}
We deploy a uniformly distributed categorical harmful queries evaluation set to evaluate the harmfulness of \llm. The evaluation set covers safety topics including \#1: Illegal Activity, \#2: Child Abuse Content, \#3: Hate/ Harass/ Violence, \#4: Malware, \#5: Physical Harm, \#6: Economic Harm, \#7: Fraud/ Deception, \#8: Adult Content, \#9: Political Campaigning, \#10: Privacy Violation Activity, and \#11: Tailored Financial Advice. 
This evaluation, which is set with the 11 main categories, can be further broken down into 89 sub-categories. The evaluation considers two scenarios, 
\begin{itemize}
    \item  
    with original inquiries (termed \textbf{Harmfulness w/o Adversarial Prompting}, the questions as they are in the harmful dataset) 
    \item
    and modified with adversarial prompting techniques (\textbf{Harmfulness w/ Adversarial Prompting}).
\end{itemize}
