\subsubsection*{Toxicity}
\begin{itemize}
        \item \textbf{Standard benchmark:} We evaluate on standard benchmark \textsc{RealToxicityPrompts} \cite{gehman2020realtoxicityprompts} to measure the properties and limitations of GPT-3.5 and GPT-4 compared to existing LLM counterparts.
        \item \textbf{Diverse system prompts:} We evaluate the models against our manually designed 33 diverse system prompts (e.g., role-playing, saying the opposite, and replacing word meaning, etc.), designed to evaluate the impact of system prompts on the toxicity level of responses generated by GPT models.
        \item \textbf{Challenging user prompts:} We evaluate the model on our 1.2K challenging user prompts generated by GPT-4 and GPT-3.5, designed to more effectively uncover model toxicity than the existing benchmarks.
\end{itemize}

