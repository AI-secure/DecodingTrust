\section{Evaluation Summary}
\label{sec:executive summary}
This is a \textbf{trustworthiness assessment} report of \llm based on DecodingTrust Benchmark \cite{wang2023decodingtrust}. This report is designed to help researchers and practitioners better understand the capabilities, limitations, and potential risks involved in deploying these state-of-the-art Large Language Models (LLMs).

\subsection{Main Results}
Toward a comprehensive trustworthiness evaluation of LLMs, we focus on the following trustworthiness perspectives and provide thorough evaluations based on different constructed scenarios, tasks, metrics, and datasets. Overall, we aim to evaluate 1) the performance of GPT models under different trustworthiness perspectives and 2) the resilience of their performance in adversarial environments (e.g., adversarial system/user prompts, demonstrations). The overall performance scores and trustworthiness assessments from each perspective are shown as follows:
\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{Images/main.png}
    \label{fig:main}
    \vspace{-0.5in}
    \caption{Overall performance of \llm from all perspectives}
\end{figure*} \\


