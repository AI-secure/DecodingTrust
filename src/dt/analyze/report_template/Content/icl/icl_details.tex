\subsubsection*{Robustness to Adversarial Demonstrations}
        \begin{itemize}
        \item \textbf{Counterfactual Demonstrations:} We evaluate in-context learning results when adding a counterfactual example of the testing input (a superficially-similar example with a different label) in the demonstrations, with goal of the evaluating if such manipulated demonstrations can mislead the model.
        \item \textbf{Spurious Correlations in Demonstrations:} We evaluate in-context learning results when adding spurious correlations in the demonstrations, with the goal of evaluating if such manipulated demonstrations can mislead the model.
        \item \textbf{Backdoors in Demonstrations:} We evaluate in-context learning results of backdoored demonstrations,  with the goal of evaluating if such manipulated demonstrations can mislead the model.         
    \end{itemize}